{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764aa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\super_krb\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\super_krb\\.venv\\Lib\\site-packages\\gradio\\interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Завантаження моделі\n",
    "from model import UNet\n",
    "MODEL_PATH = \"models/unet_model.pth\"\n",
    "model = UNet(in_channels=1, out_channels=1)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# Завантаження правил із MnM (CSV з правилами для кожного пацієнта)\n",
    "RULES_DF = pd.read_csv(\"rules.csv\") \n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Grayscale(),\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "def get_rules_for_image(filename: str):\n",
    "    basename = os.path.basename(filename)\n",
    "    row = RULES_DF[RULES_DF['filename'] == basename]\n",
    "    if not row.empty:\n",
    "        threshold = int(row.iloc[0]['threshold'])\n",
    "        morphology = row.iloc[0]['morphology']\n",
    "        return threshold, morphology\n",
    "    return 128, 'none'  \n",
    "\n",
    "def segment_mri(image: Image.Image, use_rules: bool):\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        mask = torch.sigmoid(output).squeeze().numpy()\n",
    "\n",
    "    # Базове бінаризоване зображення\n",
    "    binary_mask = (mask > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # Шлях до зображення, яке передав Gradio\n",
    "    try:\n",
    "        filename = image.info['filename']  \n",
    "    except:\n",
    "        filename = \"unknown.png\"\n",
    "\n",
    "    # Застосування правил із датасету MnM\n",
    "    if use_rules:\n",
    "        threshold, morphology = get_rules_for_image(filename)\n",
    "\n",
    "        # Застосування морфології згідно з правилами\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        if morphology == 'open-close':\n",
    "            binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "            binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        elif morphology == 'close':\n",
    "            binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        elif morphology == 'open':\n",
    "            binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "       \n",
    "\n",
    "    # Візуалізація\n",
    "    img_rgb = np.array(image.convert(\"RGB\").resize((256, 256)))\n",
    "    overlay = img_rgb.copy()\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    palette = [(0,0,255),(0,255,0),(255,0,0),(0,255,255),(255,0,255),(255,255,0)]\n",
    "    alpha = 0.5\n",
    "\n",
    "    for i, cnt in enumerate(contours):\n",
    "        color = palette[i % len(palette)]\n",
    "        mask = np.zeros_like(binary_mask)\n",
    "        cv2.drawContours(mask, [cnt], -1, 255, thickness=cv2.FILLED)\n",
    "        for c in range(3):\n",
    "            overlay[:,:,c] = np.where(mask==255,\n",
    "                                      overlay[:,:,c]*(1-alpha) + color[c]*alpha,\n",
    "                                      overlay[:,:,c])\n",
    "    out_img = cv2.addWeighted(overlay, alpha, img_rgb, 1 - alpha, 0)\n",
    "    return Image.fromarray(out_img.astype(np.uint8))\n",
    "\n",
    "# Gradio інтерфейс\n",
    "demo = gr.Interface(\n",
    "    fn=segment_mri,\n",
    "    inputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Зображення МРТ серця\"),\n",
    "        gr.Checkbox(label=\"Інтегрувати правила з датасету MnM\", value=True)\n",
    "    ],\n",
    "    outputs=gr.Image(type=\"pil\", label=\"Результат сегментації\"),\n",
    "    title=\"Сегментація МРТ серця з інтеграцією знань з MnM\",\n",
    "    submit_btn=\"Опрацювати\",\n",
    "    clear_btn=\"Очистити\"\n",
    ")\n",
    "\n",
    "demo.launch(inline=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
